{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CP to DP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAKc7GMZszxQ",
        "outputId": "1fbab8e3-b89e-4c0d-ef56-257c7fc39a96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install nltk\n",
        "!pip install benepar\n",
        "!pip install spacy\n",
        "%tensorflow_version 1.x\n",
        "import benepar , spacy,nltk\n",
        "benepar.download('benepar_en2')\n",
        "from benepar.spacy_plugin import BeneparComponent\n",
        "\n",
        "# Loading spaCyâ€™s en model and adding benepar model to its pipeline\n",
        "nlp = spacy.load('en')\n",
        "nlp.add_pipe(BeneparComponent('benepar_en2'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: benepar in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: nltk>=3.2 in /usr/local/lib/python3.6/dist-packages (from benepar) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from benepar) (1.18.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from benepar) (0.29.21)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.2->benepar) (1.15.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "[nltk_data] Downloading package benepar_en2 to /root/nltk_data...\n",
            "[nltk_data]   Package benepar_en2 is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzhY0brohxID"
      },
      "source": [
        "class Node():\n",
        "  def __init__(self):\n",
        "    self.head=None\n",
        "    self.parent=None\n",
        "    self.tag = None\n",
        "    self.count=0\n",
        "    self.child=[]\n",
        "\n",
        "def get_head_dictionary():\n",
        "  head_dict={}\n",
        "  head_dict['ADJP']={'dir':'r','tags':['RB','SBAR','RBS','RBR','FW','JJS','NP','JJR','ADJP','VBG','VBN','JJ','ADVP','NN','QP','NNS']}\n",
        "  head_dict['ADVP']={'dir':'l','tags':['RB','RBR','RBS','FW','ADVP','TO','CD','JJR','JJ','IN','NP','JJS','NN']}\n",
        "  head_dict['CONJP']={'dir':'l','tags':['CC','RB','IN']}\n",
        "  head_dict['FRAG']={'dir':'l','tags':['NNPS','NNP','NNS','NN','NP','W','SBAR','PP','IN','ADJP','JJ','ADVP','RB']}\n",
        "  head_dict['LST']={'dir':'l','tags':['LS',':']}\n",
        "  head_dict['NP']={'dir':'l','tags':['NNPS','NNP','NNS','NN','NX','JJR','CD','JJ','JJS','RB','QP','NP']}\n",
        "  head_dict['NX']=head_dict['NP']\n",
        "  head_dict['PRT']={'dir':'l','tags':['RP']}\n",
        "  head_dict['QP']={'dir':'r','tags':['$','IN','NNS','NN','JJ','RB','DT','CD','NCD','QP','JJR','JJS']}\n",
        "  head_dict['RRC']={'dir':'l','tags':['VP','NP','ADVP','ADJP','PP']}\n",
        "  head_dict['S']={'dir':'l','tags':['VP','S','SBAR','ADJP','UCP','NP']}\n",
        "  head_dict['SBAR']={'dir':'r','tags':['S','SQ','SINV','SBAR','FRAG','IN','DT']}\n",
        "  head_dict['SBARQ']={'dir':'r','tags':['SQ','S','SINV','SBARQ','FRAG']}\n",
        "  head_dict['SINV']={'dir':'l','tags':['VB','VBD','VBP','VBZ','MD','VP','S','SINV','ADJP','NP']}\n",
        "  head_dict['SQ']={'dir':'r','tags':['VB','VBD','VBP','VBZ','MD','VP','SQ']}\n",
        "  head_dict['VP']={'dir':'l','tags':['VB','VBN','MD','VBZ','VBD','VBG','VBP','VP','AUX','ADJP','NN','NNS','NP']}\n",
        "  head_dict['WHADJP']={'dir':'r','tags':['CC','WRB','JJ','ADJP']}\n",
        "  head_dict['WHADVP']={'dir':'l','tags':['CC','WRB']}\n",
        "  head_dict['WHNP']={'dir':'r','tags':['NN','WDT','WP','WP$','WHADJP','WHPP','WHNP']}\n",
        "  head_dict['ADJP']['tags'].reverse()\n",
        "  \n",
        "  return head_dict\n",
        "\n",
        "def generate_cp_input(cp):\n",
        "  cp_input=[]\n",
        "  word=''\n",
        "  for i in range(len(cp)):\n",
        "    if (cp[i]=='(' or cp[i]==')'):\n",
        "      if (word!=''):\n",
        "        cp_input.append(word)\n",
        "        word=''\n",
        "      cp_input.append(cp[i])\n",
        "    elif cp[i]==' ' or cp[i] =='\\n':\n",
        "      if(word!=''):\n",
        "        cp_input.append(word)\n",
        "        word=''\n",
        "      continue\n",
        "    else:\n",
        "      word+=cp[i]\n",
        "  #print(cp_input)\n",
        "  return cp_input\n",
        "  return convert_to_universal_tags(cp_input)\n",
        "\n",
        "head_dict=get_head_dictionary()\n",
        "\n",
        "def convert_to_dp(cp):\n",
        "\n",
        "  cp_input = generate_cp_input(cp)\n",
        "  stack = []\n",
        "  cur_word_no=1\n",
        "  dp_relations={}\n",
        "\n",
        "  AUX_VERBS=['is','were','can','could','dare','did','do','have','may','might','must','done','had','has','need','will','would','shall','should','outght']\n",
        "  \n",
        "\n",
        "  tags=set (['ROOT','LS', 'TO', 'VBN', 'WP', 'UH', 'VBG', 'JJ', 'VBZ', 'VBP', 'NN', 'DT', \n",
        "   'PRP', ':', 'WP$', 'NNPS', 'PRP$', 'WDT', '(', ')', '$', 'RB', 'RBR', 'RBS'\n",
        "  , 'VBD', 'IN', 'FW', 'RP', 'JJR', 'JJS', 'PDT', 'MD', 'VB', 'WRB', 'NNP', 'EX', 'NNS', 'SYM', 'CC', 'CD', 'POS',\n",
        "   'ADJP','ADVP','CONJP','FRAG','INTJ','LST','NAC','NP','NX','PP','WHPP','PRN','PRT',\n",
        "   'QP','RRC','S','SBAR','SBARQ','SINV','SQ','VP','UCP','WHADJP','WHNP','WHADVP','X'])\n",
        "\n",
        "  \n",
        "  for string in cp_input:\n",
        "    # if input contain ) , then pop nodes till ( is found and choose one node as head for all other nodes popped \n",
        "    if string==\")\" :\n",
        "      v = []\n",
        "      # poping nodes and storing in v\n",
        "      while (stack[-1].head!=\"(\"):\n",
        "        v.append(stack[-1])\n",
        "        stack.pop()\n",
        "      # last element popped will be parent phrase tag(NP ,VP ,S etc.) of all other nodes popped\n",
        "      root = v[-1]\n",
        "      # fin_head() returns index of element chosen as head according to Rules\n",
        "      # updating root node ,'parent' denotes string chosen as head along with its index in input sentence as 'count'\n",
        "      parent_index = find_head(v)\n",
        "      root.parent = v[parent_index].parent\n",
        "      root.count = v[parent_index].count\n",
        "      #if v[parent_index].tag != None :\n",
        "        #root.tag = v[parent_index].tag \n",
        "\n",
        "      for i in range(len(v)-1):\n",
        "        root.child.append(v[i])\n",
        "        if (i != parent_index):\n",
        "          #print(root.tag , v[i].tag)\n",
        "          dp_rel =find_dependency_relation(root,v[i])\n",
        "          #relation=dp_rel+\"(\"+root.parent+\"-\"+str(root.count)+\" , \"+v[i].parent+\"-\"+str(v[i].count)+\")\"\n",
        "          relation=(dp_rel,root.parent,\"-\",root.count,\",\",v[i].parent,\"-\",v[i].count)\n",
        "          dp_relations[v[i].count]=(relation)\n",
        "      stack.pop()\n",
        "      stack.append(root)\n",
        "\n",
        "    else:\n",
        "      node = Node()\n",
        "      node.head = string\n",
        "      node.parent = string\n",
        "      if (string not in tags):\n",
        "        node.count = cur_word_no\n",
        "        cur_word_no+=1 \n",
        "      else:\n",
        "        node.tag=string\n",
        "      if string in AUX_VERBS:\n",
        "        stack[-1].head='AUX'\n",
        "        stack[-1].parent='AUX'\n",
        "        stack[-1].tag='AUX'\n",
        "      stack.append(node)\n",
        "\n",
        "  ROOT = stack[0]\n",
        "  #relation=\"root( \"+\"ROOT-0 , \"+ ROOT.parent+\"-\"+str(ROOT.count)+\")\"\n",
        "  relation=('ROOT',ROOT.parent, '-' ,ROOT.count,',', ROOT.parent,\"-\",ROOT.count)\n",
        "  dp_relations[ROOT.count]=relation\n",
        "  dep_tree=[]\n",
        "  for key in sorted(dp_relations):\n",
        "    dep_tree.append(dp_relations[key])\n",
        "    #print(dp_relations[key])\n",
        "  return dep_tree\n",
        "\n",
        "\n",
        "def find_dependency_relation(root,depend):\n",
        "  PUNCT=['\"',',','-LRB-','-RRB-','.',':','HYPH','``']\n",
        "  ADV_TAGS=['ADV','ADVP','RB','RBR','RBS']\n",
        "  AUX_VERBS=['is','were','can','could','dare','did','do','have','may','might','must','done','had','has','need','will','would','shall','should','outght']\n",
        "  \n",
        "  root_tag = root.tag\n",
        "  child_tag = depend.tag\n",
        "  root_pos =root.count\n",
        "  child_pos = depend.count\n",
        "  #print(child_tag,child_pos,root_tag,root_pos)\n",
        "  # adverbial tag\n",
        "  if(depend.parent in AUX_VERBS):\n",
        "    return 'aux'\n",
        "  if child_tag in ADV_TAGS:\n",
        "    if root_tag in ['S','SBAR','SINV']:\n",
        "      return 'advcl'\n",
        "    if root_tag in ['NML','NP','QP']:\n",
        "      return 'npadvmod'\n",
        "    if root_tag=='VP':\n",
        "      return 'advmod'\n",
        "  if root_tag in ['VP','SINV','SQ','S','SBAR']:\n",
        "    #print(child_pos,root_pos)\n",
        "    if child_tag in ['NP','NML'] and child_pos < root_pos:\n",
        "      return 'nsubj'\n",
        "    if child_tag in ['NP','NML'] and child_pos > root_pos:\n",
        "      return 'dobj'\n",
        "    if child_tag in ['S','SQ','SBAR','SINV']:\n",
        "      return 'relcl'\n",
        "  if root_tag=='PP':\n",
        "    if child_tag in ['NP','NML']:\n",
        "      return 'pobj'\n",
        "    if child_tag in ['IN']:\n",
        "      return 'prep'\n",
        "  if child_tag=='DT':\n",
        "    return 'det'\n",
        "  if child_tag=='PRP':\n",
        "    return 'appos'\n",
        "  if child_tag=='PRP$':\n",
        "    return 'poss'\n",
        "  if child_tag in PUNCT:\n",
        "    return 'punct'\n",
        "  if child_tag in ['ADJP','ADVP','WHADJP','WHADVP','JJ'] and root_tag=='NP':\n",
        "    if child_pos < root_pos:\n",
        "      return 'amod'\n",
        "  if child_tag in ['PP','WHPP']:\n",
        "    return 'prep'\n",
        "  if child_tag in ['ADVP','SBAR'] and root_tag=='VP':\n",
        "    if child_pos < root_pos:\n",
        "      return 'advmod'\n",
        "  if child_tag=='PRT' and root_tag=='VP':\n",
        "    return 'prt'\n",
        "  if child_tag=='VP' and root_tag in ['VP','SQ','SINV']:\n",
        "    return 'vc'\n",
        "  if root_tag in ['VP','S','SBAR','SBARQ','SINV','SQ']:\n",
        "    if child_tag=='WHNP':\n",
        "      return 'nsubj'\n",
        "    return 'vmod'\n",
        "  if root_tag in ['NP','NX','WHNP']:\n",
        "    return 'nmod'\n",
        "  if root_tag in ['ADJP','ADVP','WHADJP','WHADVP']:\n",
        "    return 'amod'\n",
        "  if root_tag in ['PP','WHPP']:\n",
        "    return 'pmod'\n",
        "  return 'dep'\n",
        "\n",
        "def find_head(v):\n",
        "  # considering each pos tag occurs one time in a phrase (chunk) otherwise take care of ordering and go for head initial\n",
        "  PUNCT=['\"',',','-LRB-','-RRB-','.',':','HYPH','``']\n",
        "  tags_list = [v[i].tag for i in range(len(v)-1)]\n",
        "  tags_list.reverse()\n",
        "  #print(tags_list)\n",
        "  len_tags=len(tags_list)-1\n",
        "  root_tag=v[-1].head\n",
        "  if(len(v)==2):\n",
        "    return 0\n",
        "  if(root_tag=='PP' or root_tag=='WHPP' ):\n",
        "    prep_tags=['IN','RP']\n",
        "    i=0\n",
        "    for i in range(len(tags_list)):\n",
        "      if tags_list[i] in PUNCT:\n",
        "        continue\n",
        "      if tags_list[i] in prep_tags:\n",
        "        break\n",
        "    return i+1\n",
        "    #non puntuaction after prepposition\n",
        "    \n",
        "  if(root_tag=='PRN'):\n",
        "    for i in range(len(tags_list)):\n",
        "      if tags_list[i] in PUNCT:\n",
        "        continue\n",
        "      return i\n",
        "    #first non punctuation\n",
        "  if root_tag=='X' or root_tag=='UCP' or root_tag=='INTJ':\n",
        "    return 0\n",
        "\n",
        "  for t in head_dict[root_tag]['tags']:\n",
        "    flag=0\n",
        "    if head_dict[root_tag]['dir']=='r':\n",
        "      tags_list.reverse()\n",
        "      flag=1\n",
        "    for i in range(len(tags_list)):\n",
        "      #print('for root tag {} , head is {}'.format(root_tag,t))\n",
        "      if(tags_list[i]==t):\n",
        "        if flag==0:\n",
        "          return len_tags-i\n",
        "        else:\n",
        "          return i\n",
        "  return len(v)-2\n",
        "\n",
        "def get_actual_cp(text):\n",
        "  cp=list(nlp(text).sents)[0]._.parse_string\n",
        "  return cp\n",
        "\n",
        "def get_actual_dp(text):\n",
        "  actual_tree=[]\n",
        "  for token in nlp(text):\n",
        "    s=token.dep_,token.head.text,'-',token.head.i+1,',',token.text,'-',token.i+1\n",
        "    actual_tree.append(s)\n",
        "  \n",
        "  return actual_tree\n",
        "\n",
        "def get_head_accuracy(actual_tree,predicted_tree):\n",
        "  tp,total=0,0\n",
        "  for true,pred in zip(actual_tree,predicted_tree):\n",
        "    #print(true,pred)\n",
        "    flag=0\n",
        "    for t,p in zip(true[1:],pred[1:]):\n",
        "      if t!=p:\n",
        "        flag=1\n",
        "        break\n",
        "    if flag==0:\n",
        "      tp+=1\n",
        "    total+=1\n",
        "  return tp/total\n",
        "\n",
        "def get_relation_accuracy(actual_tree,predicted_tree):\n",
        "  tp,total=0,0\n",
        "  for true,pred in zip(actual_tree,predicted_tree):\n",
        "    #print(true,pred)\n",
        "    flag=0\n",
        "    for t,p in zip(true[0:1],pred[0:1]):\n",
        "      if t!=p:\n",
        "        flag=1\n",
        "        break\n",
        "    if flag==0:\n",
        "      tp+=1\n",
        "    total+=1\n",
        "  return tp/total\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw3IIN2iYaTa",
        "outputId": "2056c447-c4c4-4153-f804-e760a5cb6f82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# give sentence for which you want to check dependency tree\n",
        "sent=\"john runs quickly\"\n",
        "actual_cp=get_actual_cp(sent)\n",
        "actual_dp=get_actual_dp(sent)\n",
        "predicted_dp=convert_to_dp(actual_cp)\n",
        "\n",
        "head_acc=get_head_accuracy(actual_dp,predicted_dp)\n",
        "tag_acc=get_relation_accuracy(actual_dp,predicted_dp)\n",
        "print(\"predicted dependency parse tree is:\\n\")\n",
        "for relation in predicted_dp:\n",
        "  print(relation)\n",
        "print(\"head accuracy is {}\".format(head_acc))\n",
        "print(\"tag accuracy is {}\".format(tag_acc))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted dependency parse tree is:\n",
            "\n",
            "('nsubj', 'runs', '-', 2, ',', 'john', '-', 1)\n",
            "('ROOT', 'runs', '-', 2, ',', 'runs', '-', 2)\n",
            "('advmod', 'runs', '-', 2, ',', 'quickly', '-', 3)\n",
            "head accuracy is 1.0\n",
            "tag accuracy is 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}